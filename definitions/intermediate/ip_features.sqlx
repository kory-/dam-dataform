config {
  type: "table",
  schema: "dam_workflow_test",
  name: "ip_features",
  description: "IP-based feature engineering for bot detection",
  bigquery: {
    partitionBy: "log_date",
    clusterBy: ["ip"]
  },
  tags: ["feature"],
  dependencies: ["cf_logs_filtered"]
}


-- Feature engineering for bot detection (simplified version)
WITH logs AS (
  SELECT
    c_ip AS ip,
    DATE(date) AS log_date,
    DATETIME(date, time) AS dt,
    cs_uri_stem,
    sc_status,
    cs_user_agent
  FROM ${ref("cf_logs_filtered")}  -- フィルタ済みビューを参照
),
per_sec AS (
  SELECT
    *,
    COUNT(*) OVER (
      PARTITION BY ip,
                   DATETIME_TRUNC(dt, SECOND)
    ) AS rps
  FROM logs
),
ip_stats AS (
  SELECT
    ip,
    log_date,
    COUNT(*) AS req_total,
    COUNT(DISTINCT cs_uri_stem) AS unique_uri,
    SUM(IF(sc_status >= 400, 1, 0)) / COUNT(*) AS err_ratio,
    MAX(rps) AS max_rps
  FROM per_sec
  GROUP BY ip, log_date
),
ua_entropy AS (
  SELECT
    ip,
    log_date,
    -SUM(p * LN(p)) AS ua_entropy
  FROM (
    SELECT
      ip,
      log_date,
      COUNT(*) AS ua_cnt,
      SUM(COUNT(*)) OVER (PARTITION BY ip, log_date) AS total_cnt,
      COUNT(*) / SUM(COUNT(*)) OVER (PARTITION BY ip, log_date) AS p
    FROM logs
    GROUP BY ip, log_date, cs_user_agent
  )
  GROUP BY ip, log_date
)
SELECT
  s.*,
  IFNULL(e.ua_entropy, 0.0) AS ua_entropy
FROM ip_stats s
LEFT JOIN ua_entropy e
USING(ip, log_date)